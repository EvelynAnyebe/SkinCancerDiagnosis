{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ISIC 2020 IMAGE CLASSIFICATION WITH PYTORCH\n\nThis is used for building an image classifier using ISIC 2020 patient centric dataset. This work follows these steps:\n1. Get the train csv meta data\n2. Perform subsampling to solve the class imabalance problem in the data set.\n3. Prepare the data using the sub-sample","metadata":{}},{"cell_type":"markdown","source":"### Import needed library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport random as rn\nimport time\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tabulate import tabulate\n#load touch libraries\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom PIL import Image\nimport torch\n# Neural networks can be constructed using the torch.nn package.\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\nimport torchvision\nfrom torchvision import transforms, models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-25T05:13:01.456434Z","iopub.execute_input":"2022-07-25T05:13:01.456708Z","iopub.status.idle":"2022-07-25T05:13:01.476304Z","shell.execute_reply.started":"2022-07-25T05:13:01.456680Z","shell.execute_reply":"2022-07-25T05:13:01.475569Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\" Device is {}\".format(device))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:05.563336Z","iopub.execute_input":"2022-07-25T05:13:05.563592Z","iopub.status.idle":"2022-07-25T05:13:05.569163Z","shell.execute_reply.started":"2022-07-25T05:13:05.563564Z","shell.execute_reply":"2022-07-25T05:13:05.568406Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"\nprint(os.listdir(\"../input\"))\nfor (dirpath, dirnames, filenames) in os.walk(\"../input/\"):\n    print(\"Directory path: \", dirpath)\n    print(\"Folder name: \", dirnames)\n# for filenames in os.walk('/kaggle/input/'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:08.426770Z","iopub.execute_input":"2022-07-25T05:13:08.427058Z","iopub.status.idle":"2022-07-25T05:13:43.630886Z","shell.execute_reply.started":"2022-07-25T05:13:08.427005Z","shell.execute_reply":"2022-07-25T05:13:43.630077Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/siim-isic-melanoma-classification/jpeg/train'\nprint(BASE_PATH)\npath = os.path.abspath('/kaggle/input/siim-isic-melanoma-classification')\nprint(path)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:43.632808Z","iopub.execute_input":"2022-07-25T05:13:43.633069Z","iopub.status.idle":"2022-07-25T05:13:43.639828Z","shell.execute_reply.started":"2022-07-25T05:13:43.633034Z","shell.execute_reply":"2022-07-25T05:13:43.639076Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"## Loading the train meata data and preprocessing it\n\nWe load the train.csv file. Then perform the following:\n\n*   Preprocess it to remove null records\n*   Plot graph of the dataset ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(path,\"train.csv\"))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:43.640917Z","iopub.execute_input":"2022-07-25T05:13:43.641514Z","iopub.status.idle":"2022-07-25T05:13:43.705591Z","shell.execute_reply.started":"2022-07-25T05:13:43.641474Z","shell.execute_reply":"2022-07-25T05:13:43.704767Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing\nCheck the dataset for NAs and Null. Then remove nas","metadata":{}},{"cell_type":"code","source":"print(\"The number of rows and columne in train.csv: {}\".format(train_df.shape))\nprint(train_df.columns)\nprint(\"\\nDATA TYPES\\n\")\nprint(train_df.dtypes)\nprint(\"\\n=================================================\\n\")\nprint(\"\\nCOLUMN COUNT\\n\")\nprint(train_df.count())\nprint(\"\\nNULL COUNT\\n\")\nprint(train_df.isnull().sum())\ntrain_df.dropna(axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:43.707716Z","iopub.execute_input":"2022-07-25T05:13:43.708571Z","iopub.status.idle":"2022-07-25T05:13:43.786597Z","shell.execute_reply.started":"2022-07-25T05:13:43.708530Z","shell.execute_reply":"2022-07-25T05:13:43.785710Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"# Covert columns to categorical type. \n# Passed a dictionary to astype() function\ntrain_df2 = train_df.astype({'patient_id':'category',\"sex\":'category', \"diagnosis\":'category',\n                             'benign_malignant':'category','target':'category',\n                             'anatom_site_general_challenge':'category'})","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:43.788128Z","iopub.execute_input":"2022-07-25T05:13:43.788399Z","iopub.status.idle":"2022-07-25T05:13:43.814739Z","shell.execute_reply.started":"2022-07-25T05:13:43.788364Z","shell.execute_reply":"2022-07-25T05:13:43.814053Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"### After preprocessing","metadata":{}},{"cell_type":"code","source":"print(\"The number of rows and columne in train.csv: {}\".format(train_df2.shape))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:43.815855Z","iopub.execute_input":"2022-07-25T05:13:43.816155Z","iopub.status.idle":"2022-07-25T05:13:43.821949Z","shell.execute_reply.started":"2022-07-25T05:13:43.816107Z","shell.execute_reply":"2022-07-25T05:13:43.821072Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the dataset\nThese plots chech for class imbalance between benign and melanoma.\n1. Plot the distribution of the age\n2. Show image count per patient\n3. Plot the number of images according to image_diagnosis, benign or malignant, target ","metadata":{}},{"cell_type":"markdown","source":"### Helper functions are defined below","metadata":{}},{"cell_type":"code","source":"def plot_histogram(data, plot_properties):\n  \"\"\" Generic function to plot a histogram.\n      param: data- is an 1D array of data\n      param: plot_properties- a dictionary of properties like:\n      {\"title\":\"\",\"xlabel\":\"\",\"ylabel\":\"\"}\n  \"\"\"\n  plt.figure(figsize=(10, 6))\n  plt.hist(data)\n  plt.grid(False)\n  plt.title(plot_properties[\"title\"])\n  plt.xlabel(plot_properties[\"xlabel\"])\n  plt.ylabel(plot_properties[\"ylabel\"])\n  plt.show()\n\n\ndef plot_box(data, plot_properties):\n  \"\"\" Generic function to plot a box plot.\n      param: data- is an 1D array of data\n      param: plot_properties- a dictionary of properties like:\n      {\"title\":\"\",\"xlabel\":\"\",\"ylabel\":\"\"}\n  \"\"\"\n  plt.figure(figsize=(10, 6))\n  plt.boxplot(data)\n  plt.grid(False)\n  plt.title(plot_properties[\"title\"])\n  plt.xlabel(plot_properties[\"xlabel\"])\n  plt.ylabel(plot_properties[\"ylabel\"])\n  plt.show()\n    \ndef img_display(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    npimg = np.transpose(npimg, (1, 2, 0))\n    return npimg \n\ndef test_network(net, trainloader):\n\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # Create Variables for the inputs and targets\n    inputs = Variable(images)\n    targets = Variable(images)\n\n    # Clear the gradients from all Variables\n    optimizer.zero_grad()\n\n    # Forward pass, then backward pass, then update weights\n    output = net.forward(inputs)\n    loss = criterion(output, targets)\n    loss.backward()\n    optimizer.step()\n\n    return True","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:43.823533Z","iopub.execute_input":"2022-07-25T05:13:43.824062Z","iopub.status.idle":"2022-07-25T05:13:43.838656Z","shell.execute_reply.started":"2022-07-25T05:13:43.824010Z","shell.execute_reply":"2022-07-25T05:13:43.837878Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"plot_histogram(train_df2.age_approx, \n               {\"title\":\"DISTRIBUTION OF APPROXIMAGE AGE IN THE DATASET\",\n                \"xlabel\":\"APPROX AGE\",\"ylabel\":\"FREQUENCY\"});","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:43.839985Z","iopub.execute_input":"2022-07-25T05:13:43.840620Z","iopub.status.idle":"2022-07-25T05:13:44.106425Z","shell.execute_reply.started":"2022-07-25T05:13:43.840584Z","shell.execute_reply":"2022-07-25T05:13:44.105744Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"patient_group=train_df2.groupby('patient_id').image_name\nprint(\"\\nNUMBER OF IMAGES PER PATIENT\\n\")\nprint(patient_group.describe())\nprint(\"\\n Statistical description \\n\")\nprint(patient_group.count().describe())","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:44.107508Z","iopub.execute_input":"2022-07-25T05:13:44.108230Z","iopub.status.idle":"2022-07-25T05:13:46.040391Z","shell.execute_reply.started":"2022-07-25T05:13:44.108181Z","shell.execute_reply":"2022-07-25T05:13:46.038733Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nchart = sns.countplot(train_df2.diagnosis,x=\"diagnosis\",palette='Set2')\nchart.set_xticklabels(chart.get_xticklabels(), \n                      rotation=45, horizontalalignment='right')\nplt.title(\"IMAGES BY DIAGNOSIS\")\nplt.xlabel(\"ANATOMMIC DIAGNOSIS\")\nplt.ylabel(\"NUMBER OF IMAGES\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:46.042873Z","iopub.execute_input":"2022-07-25T05:13:46.043251Z","iopub.status.idle":"2022-07-25T05:13:46.349214Z","shell.execute_reply.started":"2022-07-25T05:13:46.043207Z","shell.execute_reply":"2022-07-25T05:13:46.348454Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nchart = sns.countplot(train_df2.benign_malignant,\n    x=\"benign_malignant\",\n    palette='Set2'\n)\nchart.set_xticklabels(chart.get_xticklabels(), \n                      rotation=0, horizontalalignment='right')\nplt.title(\"IMAGES BY GROUND TRUTH\")\nplt.xlabel(\"BENIGN_MALIGNANT\")\nplt.ylabel(\"NUMBER OF IMAGES\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:46.350564Z","iopub.execute_input":"2022-07-25T05:13:46.350946Z","iopub.status.idle":"2022-07-25T05:13:46.575667Z","shell.execute_reply.started":"2022-07-25T05:13:46.350910Z","shell.execute_reply":"2022-07-25T05:13:46.574928Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"#### Malignant data\nWe select all records from the dataset that are malignant.\nWe get the number of records\nWe group by patients and count the number of patients.\nWe count the number of images per patient","metadata":{}},{"cell_type":"code","source":"# selecting rows based on condition\nmalignant_df = train_df2[train_df2['target'] == 1]\nprint(\"The number of malignant records are:\",malignant_df.shape)\nmalignant_patient_group=malignant_df.groupby('patient_id').target\npatient_count=malignant_patient_group.count()\nmalignant_patient_count=patient_count.where(patient_count>0).dropna()\nmalignant_patient_data=np.column_stack((malignant_patient_count.index,malignant_patient_count))\nprint(\"\\nStatistical description\\n\")\nprint(malignant_patient_count.describe())\nplot_box(malignant_patient_data[:,1], \n{\"title\":\"DISTRIBUTION OF NUMBER OF MALIGNANT IMAGES PER PATIENT\",\"xlabel\":\"NUMBER OF IMAGES PER PATIENT\",\"ylabel\":\"FREQUENCY\"});","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:47.173886Z","iopub.execute_input":"2022-07-25T05:13:47.174446Z","iopub.status.idle":"2022-07-25T05:13:47.409495Z","shell.execute_reply.started":"2022-07-25T05:13:47.174405Z","shell.execute_reply":"2022-07-25T05:13:47.407879Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"plot_histogram(malignant_patient_data[:,1], \n{\"title\":\"DISTRIBUTION OF NUMBER OF MALIGNANT IMAGES PER PATIENT\",\"xlabel\":\"NUMBER OF IMAGES PER PATIENT\",\"ylabel\":\"FREQUENCY\"});","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:51.744332Z","iopub.execute_input":"2022-07-25T05:13:51.744826Z","iopub.status.idle":"2022-07-25T05:13:52.037126Z","shell.execute_reply.started":"2022-07-25T05:13:51.744786Z","shell.execute_reply":"2022-07-25T05:13:52.036125Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"markdown","source":"#### Benign dataset\nWe select all records from the dataset that are malignant.\nWe get the number of records\nWe group by patients and count the number of patients.\nWe count the number of images per patient","metadata":{}},{"cell_type":"code","source":"# selecting rows based on condition\nbenign_df = train_df2[train_df2['target'] == 0]\nprint(\"The number of benign records are:\",benign_df.shape)\nbenign_patient_group=benign_df.groupby('patient_id').target\nb_patient_count=benign_patient_group.count()\nbenign_patient_count=b_patient_count.where(b_patient_count>0).dropna()\nbenign_patient_data=np.column_stack((benign_patient_count.index,benign_patient_count))\nprint(\"\\nStatistical Description\\n\")\nprint(benign_patient_count.describe())\nplot_box(benign_patient_data[:,1], \n{\"title\":\"DISTRIBUTION OF NUMBER OF BENIGN IMAGES PER PATIENT\",\"xlabel\":\"NUMBER OF IMAGES PER PATIENT\",\"ylabel\":\"FREQUENCY\"});","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:54.738195Z","iopub.execute_input":"2022-07-25T05:13:54.738864Z","iopub.status.idle":"2022-07-25T05:13:54.984346Z","shell.execute_reply.started":"2022-07-25T05:13:54.738827Z","shell.execute_reply":"2022-07-25T05:13:54.982356Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"plot_histogram(benign_patient_data[:,1], \n{\"title\":\"DISTRIBUTION OF NUMBER OF BENIGN IMAGES PER PATIENT\",\"xlabel\":\"NUMBER OF IMAGES PER PATIENT\",\"ylabel\":\"FREQUENCY\"});","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:13:58.849727Z","iopub.execute_input":"2022-07-25T05:13:58.849993Z","iopub.status.idle":"2022-07-25T05:13:59.111929Z","shell.execute_reply.started":"2022-07-25T05:13:58.849961Z","shell.execute_reply":"2022-07-25T05:13:59.111241Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"markdown","source":"### Subsampling\nBased on the dataset, we start by selecting a single image per patient that is selecting images by patient Id. This is used to select images from the original image set for training and classification.\n\nSubsampling is done by checking getting the patient images that are malignant or benign. If the patient id has malignant samples, we sample 1. Else if the patient id has benign sample, we sample 1. This is done to make the dataset have enough representation of malignant as well as benign data while representing every patient.","metadata":{}},{"cell_type":"code","source":"# set seed for reproducability\nseed_value= 12321 \n# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\nos.environ['PYTHONHASHSEED']=str(seed_value)\n# 2. Set `python` built-in pseudo-random generator at a fixed value\nrn.seed(seed_value)\n# 3. Set `numpy` pseudo-random generator at a fixed value\nnp.random.seed(seed_value)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:14:03.241530Z","iopub.execute_input":"2022-07-25T05:14:03.241781Z","iopub.status.idle":"2022-07-25T05:14:03.246565Z","shell.execute_reply.started":"2022-07-25T05:14:03.241753Z","shell.execute_reply":"2022-07-25T05:14:03.245717Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"# Get patient id as category\n# Prepare two datasets:\n# for each patient_id\n    # select get records\n      # if malignant\n        # sample 1\n      # elseif benign\n        # sample 1\n\nunique_patient_id = train_df2.patient_id.cat.categories\nmalignant_df = train_df2[train_df2['target'] == 1]\n\nbenign_df = train_df2[train_df2['target'] == 0]\nsample_indices = []\n#samples per patient\nfor  patient_id in unique_patient_id:\n  patient_sample = malignant_df[malignant_df['patient_id']==patient_id]\n  if patient_sample.size:\n     sample_indices.append(patient_sample.sample(n=1, random_state=seed_value).index[0])\n  else:\n     patient_sample = benign_df[benign_df['patient_id']==patient_id]\n     if patient_sample.size: \n       sample_indices.append(patient_sample.sample(n=1, random_state=seed_value).index[0])\n\nsample_df = train_df2.loc[sample_indices]\nprint(\"Sample length\",len(sample_indices))\nsample_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:14:06.960685Z","iopub.execute_input":"2022-07-25T05:14:06.960953Z","iopub.status.idle":"2022-07-25T05:14:10.479536Z","shell.execute_reply.started":"2022-07-25T05:14:06.960923Z","shell.execute_reply":"2022-07-25T05:14:10.478729Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"markdown","source":"### Exploring and Visualizing the sub-sample\nThe following is done in this section:\n1. Count the samples by benign or malignant\n2. Plot the count","metadata":{}},{"cell_type":"code","source":"sample_df.groupby('benign_malignant').count()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:14:11.714364Z","iopub.execute_input":"2022-07-25T05:14:11.714636Z","iopub.status.idle":"2022-07-25T05:14:11.731664Z","shell.execute_reply.started":"2022-07-25T05:14:11.714606Z","shell.execute_reply":"2022-07-25T05:14:11.730571Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nchart = sns.countplot(sample_df.benign_malignant,x=\"benign_malignant\",palette='Set2')\nchart.set_xticklabels(chart.get_xticklabels(), \n                      rotation=0, horizontalalignment='right')\nplt.title(\"IMAGES BY GROUND TRUTH\")\nplt.xlabel(\"BENIGN_MALIGNANT\")\nplt.ylabel(\"NUMBER OF IMAGES\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:14:15.721112Z","iopub.execute_input":"2022-07-25T05:14:15.721605Z","iopub.status.idle":"2022-07-25T05:14:15.953281Z","shell.execute_reply.started":"2022-07-25T05:14:15.721564Z","shell.execute_reply":"2022-07-25T05:14:15.952541Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the data for classification\nIn this section, we load the images by converting them to pytouch","metadata":{}},{"cell_type":"code","source":"def set_image_file_name(row):\n    \"\"\"We create the image file name\"\"\"\n    file = row[\"image_name\"]+\".jpg\"\n    return file if os.path.exists(os.path.join(BASE_PATH, file)) else np.nan\n\nsample_df['images'] =  sample_df[['image_name','benign_malignant']].apply(lambda row: set_image_file_name(row), axis=1)\nsample_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:14:20.176401Z","iopub.execute_input":"2022-07-25T05:14:20.176670Z","iopub.status.idle":"2022-07-25T05:14:20.309938Z","shell.execute_reply.started":"2022-07-25T05:14:20.176641Z","shell.execute_reply":"2022-07-25T05:14:20.309171Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the dataset\n","metadata":{}},{"cell_type":"code","source":"batch_size = 100\nvalidation_split = .3\nshuffle_dataset = True\nrandom_seed= 42","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:14:23.744202Z","iopub.execute_input":"2022-07-25T05:14:23.744497Z","iopub.status.idle":"2022-07-25T05:14:23.750639Z","shell.execute_reply.started":"2022-07-25T05:14:23.744463Z","shell.execute_reply":"2022-07-25T05:14:23.749599Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"# sample_df.benign_malignant.unique()\ndataset_size = len(sample_df)\nindices = sample_df.index.tolist()\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:14:38.223347Z","iopub.execute_input":"2022-07-25T05:14:38.223623Z","iopub.status.idle":"2022-07-25T05:14:38.230479Z","shell.execute_reply.started":"2022-07-25T05:14:38.223594Z","shell.execute_reply":"2022-07-25T05:14:38.229328Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"markdown","source":"### Test Sub-sample","metadata":{}},{"cell_type":"code","source":"# Seperate indices that are not in the sample dataframe\ntrain_df_indices = np.array(train_df.index)\nind=np.where(np.invert(np.isin(train_df_indices,indices)))\ntest_indices = train_df_indices[ind]\ntest_sample_indices=np.random.choice(test_indices,100)\ntest_sample_df = train_df2.loc[test_sample_indices]","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:32:09.342456Z","iopub.execute_input":"2022-07-25T06:32:09.343385Z","iopub.status.idle":"2022-07-25T06:32:09.352959Z","shell.execute_reply.started":"2022-07-25T06:32:09.343336Z","shell.execute_reply":"2022-07-25T06:32:09.352221Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"test_sample_df['images'] =  test_sample_df[['image_name','benign_malignant']].apply(lambda row: set_image_file_name(row), axis=1)\ntest_sample_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:32:12.136763Z","iopub.execute_input":"2022-07-25T06:32:12.137041Z","iopub.status.idle":"2022-07-25T06:32:12.246844Z","shell.execute_reply.started":"2022-07-25T06:32:12.136994Z","shell.execute_reply":"2022-07-25T06:32:12.246002Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"test_sampler = SubsetRandomSampler(test_sample_indices)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:32:22.412425Z","iopub.execute_input":"2022-07-25T06:32:22.412725Z","iopub.status.idle":"2022-07-25T06:32:22.416530Z","shell.execute_reply.started":"2022-07-25T06:32:22.412675Z","shell.execute_reply":"2022-07-25T06:32:22.415746Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"markdown","source":"### Transforms\nTransforms are common image transformations. They can be chained together using Compose.\n\n**Normalization**\nNormalize a tensor image with mean and standard deviation. Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, this transform will normalize each channel of the input torch.*Tensor i.e. input[channel] = (input[channel] - mean[channel]) / std[channel] \n\n**Convert a PIL Image or numpy.ndarray to tensor**\nConverts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:15:03.408755Z","iopub.execute_input":"2022-07-25T05:15:03.409032Z","iopub.status.idle":"2022-07-25T05:15:03.413540Z","shell.execute_reply.started":"2022-07-25T05:15:03.408985Z","shell.execute_reply":"2022-07-25T05:15:03.412815Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"markdown","source":"### Create custom dataset class\n\n> A custom dataset which contain following functions is defined to be used by data loader later on.\n1. init() function where the initial logic happens.\n2. getitem() function returns the data and labels.","metadata":{}},{"cell_type":"code","source":"class Lesion_Dataset(Dataset):\n    def __init__(self, img_data,img_path,transform=None):\n        self.img_path = img_path\n        self.transform = transform\n        self.img_data = img_data\n        \n    def __len__(self):\n        return len(self.img_data)\n    \n    def __getitem__(self, index):\n        img_name = os.path.join(self.img_path,self.img_data.loc[index, 'images'])\n        image = Image.open(img_name)\n        #image = image.convert('RGB')\n        image = image.resize((300,300))\n        label = torch.tensor(self.img_data.loc[index, 'target'])\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:15:06.403180Z","iopub.execute_input":"2022-07-25T05:15:06.403765Z","iopub.status.idle":"2022-07-25T05:15:06.410944Z","shell.execute_reply.started":"2022-07-25T05:15:06.403730Z","shell.execute_reply":"2022-07-25T05:15:06.410069Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"# Create the dataset\ndataset = Lesion_Dataset(sample_df,BASE_PATH,transform)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:15:09.645440Z","iopub.execute_input":"2022-07-25T05:15:09.645702Z","iopub.status.idle":"2022-07-25T05:15:09.650022Z","shell.execute_reply.started":"2022-07-25T05:15:09.645674Z","shell.execute_reply":"2022-07-25T05:15:09.648986Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"test_dataset = Lesion_Dataset(test_sample_df,BASE_PATH,transform)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:32:37.406385Z","iopub.execute_input":"2022-07-25T06:32:37.406637Z","iopub.status.idle":"2022-07-25T06:32:37.410813Z","shell.execute_reply.started":"2022-07-25T06:32:37.406612Z","shell.execute_reply":"2022-07-25T06:32:37.409808Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"# create our loaders\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n                                           sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(dataset, batch_size=1,\n                                                sampler=valid_sampler)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:15:13.205636Z","iopub.execute_input":"2022-07-25T05:15:13.205929Z","iopub.status.idle":"2022-07-25T05:15:13.212997Z","shell.execute_reply.started":"2022-07-25T05:15:13.205897Z","shell.execute_reply":"2022-07-25T05:15:13.212046Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n                                                sampler=test_sampler)\nprint(\"Training and validation loader completed \")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:32:58.537517Z","iopub.execute_input":"2022-07-25T06:32:58.537924Z","iopub.status.idle":"2022-07-25T06:32:58.544836Z","shell.execute_reply.started":"2022-07-25T06:32:58.537879Z","shell.execute_reply":"2022-07-25T06:32:58.544103Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"# let's see the number of positive and negative image\n# a,b=np.unique(df[\"target\"],return_counts=True)\n\n# from sklearn.model_selection import train_test_split\n# train,valid=train_test_split(df,test_size=0.2)\n\n# #now split train to get some image for testing\n# train,test=train_test_split(train,test_size=.01)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:12:18.956080Z","iopub.status.idle":"2022-07-25T05:12:18.956701Z","shell.execute_reply.started":"2022-07-25T05:12:18.956438Z","shell.execute_reply":"2022-07-25T05:12:18.956479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing images in the dataset\n","metadata":{}},{"cell_type":"code","source":"dataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\nlesion_types={0:'benign', 1:'malignant'} \nfig, axis = plt.subplots(3, 5, figsize=(15, 10))\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        image, label = images[i], labels[i]\n        ax.imshow(img_display(image)) # add image\n        ax.set(title = f\"{lesion_types[label.item()]}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:15:17.102678Z","iopub.execute_input":"2022-07-25T05:15:17.102964Z","iopub.status.idle":"2022-07-25T05:15:44.527270Z","shell.execute_reply.started":"2022-07-25T05:15:17.102933Z","shell.execute_reply":"2022-07-25T05:15:44.526492Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"## Performing classification\n\nHere we perform classification using:\n1. Transfer learning: with a model such as DenseNet. Let's print out the model architecture so we can see what's going on.","metadata":{}},{"cell_type":"code","source":"model = models.densenet121(pretrained=True)\n# model\n# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False\n\nfrom collections import OrderedDict\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(1024, 500)),\n                          ('relu', nn.ReLU()),\n                          ('fc2', nn.Linear(500, 2)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \nmodel.classifier = classifier","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:15:44.528937Z","iopub.execute_input":"2022-07-25T05:15:44.529390Z","iopub.status.idle":"2022-07-25T05:15:49.146935Z","shell.execute_reply.started":"2022-07-25T05:15:44.529350Z","shell.execute_reply":"2022-07-25T05:15:49.146203Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\" Device is {}\".format(device))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:15:49.148377Z","iopub.execute_input":"2022-07-25T05:15:49.148621Z","iopub.status.idle":"2022-07-25T05:15:49.153442Z","shell.execute_reply.started":"2022-07-25T05:15:49.148586Z","shell.execute_reply":"2022-07-25T05:15:49.152733Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"CUDA GPU is used instead of cuda for training","metadata":{}},{"cell_type":"code","source":"# for device in ['cpu', 'cuda']:\n\n#     criterion = nn.NLLLoss()\n#     # Only train the classifier parameters, feature parameters are frozen\n#     optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n\n#     model.to(device)\n\n#     for ii, (inputs, labels) in enumerate(train_loader):\n\n#         # Move input and label tensors to the GPU\n#         inputs, labels = inputs.to(device), labels.to(device)\n\n#         start = time.time()\n\n#         outputs = model.forward(inputs)\n#         loss = criterion(outputs, labels)\n#         loss.backward()\n#         optimizer.step()\n\n#         if ii==3:\n#             break\n        \n#     print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:15:49.155355Z","iopub.execute_input":"2022-07-25T05:15:49.155840Z","iopub.status.idle":"2022-07-25T05:15:49.163294Z","shell.execute_reply.started":"2022-07-25T05:15:49.155804Z","shell.execute_reply":"2022-07-25T05:15:49.162511Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"criterion = nn.NLLLoss()\n\n# Only train the classifier parameters, feature parameters are frozen\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n\nmodel.to(device);","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:15:49.747456Z","iopub.execute_input":"2022-07-25T05:15:49.748252Z","iopub.status.idle":"2022-07-25T05:15:52.951572Z","shell.execute_reply.started":"2022-07-25T05:15:49.748206Z","shell.execute_reply":"2022-07-25T05:15:52.950810Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nsteps = 0\nrunning_loss = 0\nprint_every = 5\nfor epoch in range(epochs):\n    for inputs, labels in train_loader:\n        steps += 1\n        # Move input and label tensors to the default device\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        \n        if steps % print_every == 0:\n            test_loss = 0\n            accuracy = 0\n            model.eval()\n            with torch.no_grad():\n                for inputs, labels in validation_loader:\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    logps = model.forward(inputs)\n                    batch_loss = criterion(logps, labels)\n                    \n                    test_loss += batch_loss.item()\n                    \n                    # Calculate accuracy\n                    ps = torch.exp(logps)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n                    \n            print(f\"Epoch {epoch+1}/{epochs}.. \"\n                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n                  f\"Test loss: {test_loss/len(validation_loader):.3f}.. \"\n                  f\"Test accuracy: {accuracy/len(validation_loader):.3f}\")\n            running_loss = 0\n            model.train()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:36:36.153563Z","iopub.execute_input":"2022-07-25T05:36:36.153855Z","iopub.status.idle":"2022-07-25T05:49:53.445718Z","shell.execute_reply.started":"2022-07-25T05:36:36.153825Z","shell.execute_reply":"2022-07-25T05:49:53.444901Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating the model performance\nHere, the following is done.\n1. Sample a test data from the original dataset.\n2. Test the model for accuracy","metadata":{}},{"cell_type":"code","source":"dataiter_test = iter(test_loader)\ntest_images, test_labels = dataiter_test.next()\ntest_inputs = test_images.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:33:44.689310Z","iopub.execute_input":"2022-07-25T06:33:44.689844Z","iopub.status.idle":"2022-07-25T06:33:45.070817Z","shell.execute_reply.started":"2022-07-25T06:33:44.689802Z","shell.execute_reply":"2022-07-25T06:33:45.070069Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"outputs = model(test_inputs)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:33:47.723096Z","iopub.execute_input":"2022-07-25T06:33:47.723742Z","iopub.status.idle":"2022-07-25T06:33:47.754707Z","shell.execute_reply.started":"2022-07-25T06:33:47.723697Z","shell.execute_reply":"2022-07-25T06:33:47.753950Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"classes  = (\"benign\", \"malignant\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:33:51.550400Z","iopub.execute_input":"2022-07-25T06:33:51.550897Z","iopub.status.idle":"2022-07-25T06:33:51.554559Z","shell.execute_reply.started":"2022-07-25T06:33:51.550859Z","shell.execute_reply":"2022-07-25T06:33:51.553663Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"markdown","source":"Using the test dataset","metadata":{}},{"cell_type":"code","source":"_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', f'{classes[predicted[0]]:5s}')\nprint('Actual label: ', f'{classes[test_labels[0]]:5s}')","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:33:53.952969Z","iopub.execute_input":"2022-07-25T06:33:53.953569Z","iopub.status.idle":"2022-07-25T06:33:53.959616Z","shell.execute_reply.started":"2022-07-25T06:33:53.953529Z","shell.execute_reply":"2022-07-25T06:33:53.958828Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"# prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# again no gradients needed\nwith torch.no_grad():\n    for data in test_loader:\n        test_images, test_labels = data\n        test_inputs, input_labels = test_images.to(device), test_labels.to(device)\n        outputs = model(test_inputs)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(input_labels, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:34:03.178135Z","iopub.execute_input":"2022-07-25T06:34:03.178779Z","iopub.status.idle":"2022-07-25T06:34:34.986231Z","shell.execute_reply.started":"2022-07-25T06:34:03.178742Z","shell.execute_reply":"2022-07-25T06:34:34.985436Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"total_pred","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:35:29.915568Z","iopub.execute_input":"2022-07-25T06:35:29.915847Z","iopub.status.idle":"2022-07-25T06:35:29.921294Z","shell.execute_reply.started":"2022-07-25T06:35:29.915817Z","shell.execute_reply":"2022-07-25T06:35:29.920465Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"correct_pred","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:35:44.608923Z","iopub.execute_input":"2022-07-25T06:35:44.609533Z","iopub.status.idle":"2022-07-25T06:35:44.616621Z","shell.execute_reply.started":"2022-07-25T06:35:44.609495Z","shell.execute_reply":"2022-07-25T06:35:44.615900Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    print(classname,correct_count)\n    accuracy = 0 if correct_count == 0 else 100 * float(correct_count) / total_pred[classname]\n    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')","metadata":{"execution":{"iopub.status.busy":"2022-07-25T06:36:52.294535Z","iopub.execute_input":"2022-07-25T06:36:52.295133Z","iopub.status.idle":"2022-07-25T06:36:52.301741Z","shell.execute_reply.started":"2022-07-25T06:36:52.295097Z","shell.execute_reply":"2022-07-25T06:36:52.300860Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"markdown","source":"Save the model","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-07-25T05:12:18.980036Z","iopub.status.idle":"2022-07-25T05:12:18.980616Z","shell.execute_reply.started":"2022-07-25T05:12:18.980379Z","shell.execute_reply":"2022-07-25T05:12:18.980405Z"},"trusted":true},"execution_count":null,"outputs":[]}]}